# Endpoints relacionados ao ChatGPT/OpenAI

from flask import Blueprint, request, jsonify, send_file, current_app
import os
import uuid
import shutil
import re
import tempfile
from werkzeug.utils import secure_filename
from ai.openai_service import extract_fields_with_openai
import pypdf
from config import Config
from security import secure_manager
import pandas as pd

ai_bp = Blueprint('ai', __name__)

# Dicion√°rio global para armazenar arquivos de memorial
memorial_files = {}

def allowed_file(filename):
    """Verifica se o arquivo tem extens√£o permitida"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in Config.ALLOWED_EXTENSIONS

@ai_bp.route('/api/process-file', methods=['POST'])
def process_file_chatgpt():
    """Endpoint otimizado para processamento com ChatGPT - extrai texto diretamente do PDF"""
    temp_file_path = None
    user_ip = request.remote_addr
    
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        if not allowed_file(file.filename):
            return jsonify({'error': 'Apenas arquivos PDF s√£o permitidos'}), 400
        
        # Obter tipo de servi√ßo
        service_type = request.form.get('service', 'matricula')
        print(f"üéØ Servi√ßo recebido: {service_type}")
        
        original_filename = secure_filename(file.filename or 'unknown.pdf')
        
        # Processar arquivo de forma segura
        if Config.SECURE_PROCESSING:
            temp_file_path, file_id = secure_manager.process_file_securely(
                file, original_filename, user_ip
            )
        else:
            # Fallback para processamento n√£o seguro (apenas para compatibilidade)
            file_id = str(uuid.uuid4())
            upload_filename = f"{file_id}_{original_filename}"
            temp_file_path = os.path.join(Config.UPLOAD_FOLDER, upload_filename)
            file.save(temp_file_path)
        
        # Extrair texto diretamente do PDF (sem OCR)
        text_content = ""
        try:
            # Descriptografar se necess√°rio
            if Config.SECURE_PROCESSING and Config.ENCRYPT_TEMP_FILES:
                temp_file_path = secure_manager.decrypt_file(temp_file_path)
            
            with open(temp_file_path, 'rb') as f:
                pdf_reader = pypdf.PdfReader(f)
                for page in pdf_reader.pages:
                    text_content += page.extract_text() + "\n"
        except Exception as e:
            return jsonify({'error': f'Erro ao extrair texto do PDF: {str(e)}'}), 500
        
        # Limpar e normalizar texto
        text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
        
        # Se o texto estiver vazio, retornar erro (ChatGPT n√£o usa OCR)
        if not text_content or len(text_content.strip()) < 50:
            return jsonify({
                'error': 'PDF n√£o cont√©m texto pesquis√°vel. Use OCR Tesseract para PDFs escaneados.',
                'message': 'O ChatGPT funciona apenas com PDFs que j√° cont√™m texto.'
            }), 400
        
        # Obter modelo selecionado
        model = request.form.get('model', 'gpt-3.5-turbo')
        print(f"üéØ Modelo recebido no backend: {model}")
        
        # Extrair campos com OpenAI
        campos = extract_fields_with_openai(text_content, model=model, service_type=service_type)
        
        # Limpar arquivo tempor√°rio ap√≥s processamento
        if Config.SECURE_PROCESSING and temp_file_path:
            secure_manager.cleanup_file(temp_file_path, user_ip)
        
        return jsonify({
            'success': True,
            'message': f'PDF processado e campos extra√≠dos com ChatGPT ({service_type})!',
            'original_filename': original_filename,
            'file_id': file_id,
            'campos': campos,
            'model': model,
            'service_type': service_type,
            'text_length': len(text_content),
            'used_ocr_fallback': len(text_content.strip()) < 50,
            'secure_processing': Config.SECURE_PROCESSING
        })
        
    except Exception as e:
        # Garantir limpeza em caso de erro
        if Config.SECURE_PROCESSING and temp_file_path:
            secure_manager.cleanup_file(temp_file_path, user_ip)
        return jsonify({'error': f'Erro interno do servidor: {str(e)}'}), 500 

@ai_bp.route('/api/certidao', methods=['POST'])
def process_certidao():
    """Endpoint para processar PDF de matr√≠cula, extrair campos via OpenAI e gerar certid√£o personalizada"""
    from ai.ocr_service import extract_text_from_pdf, process_pdf_with_ocr
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4
    import io

    temp_file_path = None
    user_ip = request.remote_addr

    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        if not allowed_file(file.filename):
            return jsonify({'error': 'Apenas arquivos PDF s√£o permitidos'}), 400

        # Obter tipo de certid√£o e modelo
        tipo_certidao = 'STNegativa'
        motivo_certidao = 'N√£o h√° √¥nus real identificado.'

        # O restante do c√≥digo permanece igual, mas usar tipo_certidao para o t√≠tulo
        # e retornar tipo_certidao e motivo_certidao no response.

        original_filename = secure_filename(file.filename or 'unknown.pdf')
        # Processar arquivo de forma segura
        if Config.SECURE_PROCESSING:
            temp_file_path, file_id = secure_manager.process_file_securely(
                file, original_filename, user_ip
            )
        else:
            file_id = str(uuid.uuid4())
            upload_filename = f"{file_id}_{original_filename}"
            temp_file_path = os.path.join(Config.UPLOAD_FOLDER, upload_filename)
            file.save(temp_file_path)

        # Extrair texto do PDF (OCR se necess√°rio)
        text_content = ""
        temp_ocr_path = None
        
        try:
            # Descriptografar se necess√°rio
            if Config.SECURE_PROCESSING and Config.ENCRYPT_TEMP_FILES:
                temp_file_path = secure_manager.decrypt_file(temp_file_path)
            
            # Tentar extrair texto diretamente primeiro
            with open(temp_file_path, 'rb') as f:
                pdf_reader = pypdf.PdfReader(f)
                for page in pdf_reader.pages:
                    text_content += page.extract_text() + "\n"
        except Exception as e:
            print(f"‚ùå Erro ao extrair texto diretamente: {str(e)}")
            text_content = ""
        
        # Limpar e normalizar texto
        text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
        
        # Se n√£o houver texto suficiente, tentar OCR
        if not text_content or len(text_content.strip()) < 50:
            print("üìÑ Tentando OCR para extrair texto...")
            try:
                temp_ocr_path = temp_file_path + '_ocr.pdf'
                ocr_result = process_pdf_with_ocr(temp_file_path, temp_ocr_path)
                if ocr_result.get('success'):
                    print("‚úÖ OCR bem-sucedido, extraindo texto...")
                    text_content = extract_text_from_pdf(temp_ocr_path)
                    # Limpar novamente
                    text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
                else:
                    print(f"‚ùå OCR falhou: {ocr_result.get('error', 'Erro desconhecido')}")
                    # Tentar processar mesmo com pouco texto
                    if len(text_content.strip()) > 10:
                        print("‚ö†Ô∏è Continuando com texto m√≠nimo extra√≠do...")
                    else:
                        return jsonify({
                            'error': 'N√£o foi poss√≠vel extrair texto suficiente do PDF.',
                            'details': 'O arquivo pode estar corrompido, protegido por senha, ou ser uma imagem escaneada de baixa qualidade.',
                            'suggestion': 'Tente com um arquivo PDF diferente ou verifique se o arquivo n√£o est√° protegido.',
                            'ocr_error': ocr_result.get('error', 'Erro desconhecido')
                        }), 400
            except Exception as ocr_error:
                print(f"‚ùå Erro durante OCR: {str(ocr_error)}")
                # Se temos pelo menos algum texto, continuar
                if len(text_content.strip()) > 10:
                    print("‚ö†Ô∏è Continuando com texto m√≠nimo extra√≠do...")
                else:
                    return jsonify({
                        'error': 'Erro durante processamento OCR.',
                        'details': str(ocr_error),
                        'suggestion': 'Verifique se o arquivo √© um PDF v√°lido e n√£o est√° corrompido.'
                    }), 400
        
        # Verificar se temos texto suficiente para processar
        if not text_content or len(text_content.strip()) < 10:
            return jsonify({
                'error': 'Texto insuficiente para processamento.',
                'details': f'Extra√≠do apenas {len(text_content)} caracteres.',
                'suggestion': 'O arquivo pode estar vazio ou n√£o conter texto leg√≠vel.',
                'text_preview': text_content[:200] if text_content else ''
            }), 400
        
        print(f"‚úÖ Texto extra√≠do com sucesso: {len(text_content)} caracteres")
        
        # Debug: mostrar preview do texto extra√≠do
        print(f"üìÑ Preview do texto (primeiros 500 chars): {text_content[:500]}")
        
        # Extrair campos com OpenAI
        print("ü§ñ Iniciando extra√ß√£o com IA...")
        model = request.form.get('model', 'gpt-3.5-turbo')
        if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY.strip() == '':
            return jsonify({
                'error': 'Chave da API OpenAI n√£o configurada.',
                'details': 'Configure a vari√°vel de ambiente OPENAI_API_KEY para usar a funcionalidade de IA.',
                'suggestion': 'Adicione sua chave da OpenAI nas configura√ß√µes do sistema.'
            }), 500
        campos = None
        temp_ocr_path = None
        try:
            campos = extract_fields_with_openai(text_content, model=model, service_type='certidao')
        except Exception as ia_error:
            print(f"‚ùå Erro na extra√ß√£o de campos pela IA: {ia_error}")
            return jsonify({'error': 'Erro ao extrair campos da certid√£o com IA.', 'details': str(ia_error)}), 500

        # --- L√≥gica para identificar o tipo de certid√£o ---
        if not campos or not isinstance(campos, dict):
            return jsonify({'error': 'N√£o foi poss√≠vel extrair os campos necess√°rios da certid√£o.'}), 500
        tipo_certidao = 'STNegativa'
        motivo_certidao = 'N√£o h√° √¥nus real identificado.'
        onus = (campos.get('onus_certidao_negativa') or '').lower()
        descricao = (campos.get('descricao_imovel') or '').lower()
        enfiteuta = (campos.get('enfiteuta') or '').lower()
        senhorio = (campos.get('senhorio_direto') or '').lower()
        if 'foreiro' in descricao or 'enfiteuta' in descricao or enfiteuta or senhorio:
            tipo_certidao = 'STForeiro'
            motivo_certidao = 'Im√≥vel foreiro (dom√≠nio √∫til/enfiteuta) identificado.'
        elif any(palavra in onus for palavra in ['hipoteca', 'aliena√ß√£o', 'penhora', '√¥nus', 'restri√ß√£o', 'gravame', 'fiduci√°ria', 'a√ß√£o judicial', 'usucapi√£o', 'usufruto', 'servid√£o', 'penhor', 'protesto', 'bloqueio', 'penalidade', 'penal', 'a√ß√£o', 'execu√ß√£o']):
            tipo_certidao = 'STPositiva'
            motivo_certidao = '√înus real ou restri√ß√£o identificado.'
        else:
            tipo_certidao = 'STNegativa'
            motivo_certidao = 'N√£o h√° √¥nus real identificado.'

        # O restante do c√≥digo permanece igual, mas usar tipo_certidao para o t√≠tulo
        # e retornar tipo_certidao e motivo_certidao no response.

        # Gerar PDF personalizado da certid√£o conforme o tipo (layout avan√ßado)
        from reportlab.lib.units import cm
        from reportlab.lib.styles import ParagraphStyle
        from reportlab.platypus import SimpleDocTemplate, Paragraph
        from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.pdfbase import pdfmetrics
        from datetime import datetime
        from reportlab.lib import colors
        import io

        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4,
            leftMargin=3*cm, rightMargin=3*cm, topMargin=3*cm, bottomMargin=2*cm)

        # Fonte Times New Roman se dispon√≠vel
        try:
            pdfmetrics.registerFont(TTFont('TimesNewRoman', 'times.ttf'))
            base_font = 'TimesNewRoman'
        except:
            base_font = 'Times-Roman'

        # Estilos
        style_title = ParagraphStyle('title', fontName=base_font, fontSize=13, alignment=TA_CENTER, leading=18, spaceAfter=10, textDecoration='underline', fontWeight='bold')
        style_body = ParagraphStyle('body', fontName=base_font, fontSize=12, alignment=TA_JUSTIFY, leading=19)

        # Cores
        cor_vermelho = '#FF0000'
        cor_azul = '#0070C0'
        cor_azul_escuro = '#002060'

        # Data
        data_certidao = datetime.now().strftime('%d/%m/%Y')

        # Montar o par√°grafo principal
        texto = (
            '<b>CERTIFICO</b>, nos termos dos arts. 17 e 19, ¬ß9¬∫, da Lei n.¬∫ 6.015/1973, e art. 123, caput, do Provimento n.¬∫ 149/2023, do Conselho Nacional de Justi√ßa - CNJ, que, revendo os livros, arquivos e sistemas eletr√¥nicos desta Serventia, inclusive cadastro interno de a√ß√µes reais e pessoais reipersecut√≥rias envolvendo im√≥veis desta circunscri√ß√£o, encontrei o lan√ßamento relativo ao registro de im√≥vel seguinte: '
            f'<b><u>CADASTRO NACIONAL DE MATR√çCULA - CNM:</u></b> <font color="{cor_vermelho}">{campos.get("cnm", "")}</font>, '
            f'<b><u>DESCRI√á√ÉO DO IM√ìVEL:</u></b> <font color="{cor_azul}">{campos.get("descricao_imovel", "")}</font>, '
        )
        if campos.get('senhorio_direto'):
            texto += f'<b><u>SENHORIO DIRETO:</u></b> {campos.get("senhorio_direto")}, '
        if campos.get('enfiteuta'):
            texto += f'<b><u>ENFITEUTA:</u></b> {campos.get("enfiteuta")}, '
        texto += f'<b><u>PROPRIET√ÅRIO(S):</u></b> <font color="{cor_azul_escuro}">{campos.get("proprietarios", "")}</font>, '
        texto += f'<b><u>INSCRI√á√ÉO IMOBILI√ÅRIA:</u></b> <font color="{cor_azul_escuro}">{campos.get("inscricao_imobiliaria", "")}</font>, '
        if campos.get('rip'):
            texto += f'<b><u>REGISTRO IMOBILI√ÅRIO PATRIMONIAL (RIP):</u></b> {campos.get("rip")}, '
        texto += f'<b><u>DIREITOS, √îNUS REAIS E RESTRI√á√ïES JUDICIAIS E ADMINISTRATIVAS:</u></b> <b>{campos.get("onus_certidao_negativa", "")}</b>. '
        texto += f'O referido √© verdade e dou f√©. S√£o Lu√≠s/MA, {data_certidao}. '
        texto += f'<b>Emolumentos:</b> Certid√£o: Ato 16.24.4 - <font color="{cor_azul}">R$ 87,31</font>; FEMP: <font color="{cor_azul}">R$ 3,49</font>; FADEP: <font color="{cor_azul}">R$ 3,49</font>; FERC: <font color="{cor_azul}">R$ 2,61</font>. '
        texto += '<b>Jo√£o Gabriel Santos Barros, Escrevente Autorizado.</b> '
        texto += f'<br/><b><font color="{cor_azul_escuro}">Validade: 30 dias.</font></b>'

        # Ajustar tags HTML para ReportLab
        texto = texto.replace('class="bold"', 'b').replace('class="underline"', 'u')
        texto = texto.replace('b u', 'b u').replace('u b', 'u b')  # garantir ordem
        texto = texto.replace('style="color:'+cor_azul_escuro+'"', f'color="{cor_azul_escuro}"')

        from reportlab.platypus import Flowable
        
        elements: list[Flowable] = [
            Paragraph('<u><b>CERTID√ÉO DE SITUA√á√ÉO JUR√çDICA DO IM√ìVEL</b></u>', style_title),
            Paragraph(texto, style_body)
        ]

        doc.build(elements)
        buffer.seek(0)

        # Limpar arquivos tempor√°rios
        if Config.SECURE_PROCESSING and temp_file_path:
            secure_manager.cleanup_file(temp_file_path, user_ip)
        if 'temp_ocr_path' in locals() and temp_ocr_path and os.path.exists(temp_ocr_path):
            try:
                os.remove(temp_ocr_path)
            except Exception:
                pass

        # Debug: mostrar campos extra√≠dos antes de gerar o PDF
        print("Campos extra√≠dos para o PDF:", campos)
        # Mapeamento para garantir nomes corretos
        campos['cnm'] = campos.get('cnm') or campos.get('matricula') or ''
        campos['descricao_imovel'] = campos.get('descricao_imovel') or campos.get('descricao') or ''
        campos['proprietarios'] = campos.get('proprietarios') or campos.get('proprietario') or ''
        campos['inscricao_imobiliaria'] = campos.get('inscricao_imobiliaria') or campos.get('inscricao') or ''
        campos['onus_certidao_negativa'] = campos.get('onus_certidao_negativa') or campos.get('onus') or ''
        campos['senhorio_enfiteuta'] = campos.get('senhorio_enfiteuta') or campos.get('senhorio') or campos.get('enfiteuta') or ''
        campos['rip'] = campos.get('rip') or ''
        campos['nome_solicitante'] = campos.get('nome_solicitante') or campos.get('solicitante') or ''

        # Retornar PDF gerado e info do tipo/motivo
        return (buffer.getvalue(), 200, {
            'Content-Type': 'application/pdf',
            'Content-Disposition': f'attachment; filename=certidao_{tipo_certidao}_{file_id}.pdf',
            'X-Certidao-Tipo': tipo_certidao,
            'X-Certidao-Motivo': motivo_certidao
        })
    except Exception as e:
        # Garantir limpeza em caso de erro
        if Config.SECURE_PROCESSING and temp_file_path:
            secure_manager.cleanup_file(temp_file_path, user_ip)
        if 'temp_ocr_path' in locals() and temp_ocr_path and os.path.exists(temp_ocr_path):
            try:
                os.remove(temp_ocr_path)
            except Exception:
                pass
        return jsonify({'error': f'Erro interno do servidor: {str(e)}'}), 500 

@ai_bp.route('/api/qualificacao', methods=['POST'])
def process_qualificacao():
    """Endpoint para processar m√∫ltiplos arquivos para an√°lise de qualifica√ß√£o"""
    temp_files = []
    user_ip = request.remote_addr
    
    try:
        if 'files[]' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        
        files = request.files.getlist('files[]')
        if not files or all(file.filename == '' for file in files):
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        
        # Validar arquivos
        valid_files = []
        for file in files:
            if file.filename and allowed_file(file.filename):
                valid_files.append(file)
            else:
                return jsonify({'error': f'Arquivo inv√°lido: {file.filename}. Apenas PDFs s√£o permitidos.'}), 400
        
        if not valid_files:
            return jsonify({'error': 'Nenhum arquivo v√°lido encontrado'}), 400
        
        print(f"üìÅ Processando {len(valid_files)} arquivos para qualifica√ß√£o...")
        
        # Processar cada arquivo individualmente
        documentos_analisados = []
        textos_extraidos = []
        
        for i, file in enumerate(valid_files):
            try:
                original_filename = secure_filename(file.filename or f'arquivo_{i}.pdf')
                print(f"üìÑ Processando arquivo {i+1}/{len(valid_files)}: {original_filename}")
                
                # Processar arquivo de forma segura
                if Config.SECURE_PROCESSING:
                    temp_file_path, file_id = secure_manager.process_file_securely(
                        file, original_filename, user_ip
                    )
                else:
                    file_id = str(uuid.uuid4())
                    upload_filename = f"{file_id}_{original_filename}"
                    temp_file_path = os.path.join(Config.UPLOAD_FOLDER, upload_filename)
                    file.save(temp_file_path)
                
                temp_files.append(temp_file_path)
                
                # Extrair texto do PDF
                text_content = ""
                try:
                    # Descriptografar se necess√°rio
                    if Config.SECURE_PROCESSING and Config.ENCRYPT_TEMP_FILES:
                        temp_file_path = secure_manager.decrypt_file(temp_file_path)
                    
                    # Tentar extrair texto diretamente
                    with open(temp_file_path, 'rb') as f:
                        pdf_reader = pypdf.PdfReader(f)
                        for page in pdf_reader.pages:
                            text_content += page.extract_text() + "\n"
                except Exception as e:
                    print(f"‚ùå Erro ao extrair texto de {original_filename}: {str(e)}")
                    text_content = ""
                
                # Limpar e normalizar texto
                text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
                
                # Se n√£o houver texto suficiente, tentar OCR
                if not text_content or len(text_content.strip()) < 50:
                    print(f"üìÑ Tentando OCR para {original_filename}...")
                    try:
                        from ai.ocr_service import process_pdf_with_ocr, extract_text_from_pdf
                        temp_ocr_path = temp_file_path + '_ocr.pdf'
                        ocr_result = process_pdf_with_ocr(temp_file_path, temp_ocr_path)
                        if ocr_result.get('success'):
                            print(f"‚úÖ OCR bem-sucedido para {original_filename}")
                            text_content = extract_text_from_pdf(temp_ocr_path)
                            text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
                        else:
                            print(f"‚ùå OCR falhou para {original_filename}")
                    except Exception as ocr_error:
                        print(f"‚ùå Erro durante OCR de {original_filename}: {str(ocr_error)}")
                
                if text_content and len(text_content.strip()) > 10:
                    documentos_analisados.append({
                        'filename': original_filename,
                        'file_id': file_id,
                        'text_length': len(text_content),
                        'text_preview': text_content[:200]
                    })
                    textos_extraidos.append(f"=== DOCUMENTO: {original_filename} ===\n{text_content}\n")
                else:
                    print(f"‚ö†Ô∏è Texto insuficiente em {original_filename}")
                    documentos_analisados.append({
                        'filename': original_filename,
                        'file_id': file_id,
                        'text_length': 0,
                        'error': 'Texto insuficiente ou n√£o leg√≠vel'
                    })
                
            except Exception as e:
                print(f"‚ùå Erro ao processar {original_filename}: {str(e)}")
                documentos_analisados.append({
                    'filename': original_filename,
                    'file_id': str(uuid.uuid4()),
                    'error': str(e)
                })
        
        # Se n√£o h√° textos suficientes, retornar erro
        if not textos_extraidos:
            return jsonify({
                'error': 'N√£o foi poss√≠vel extrair texto suficiente dos documentos.',
                'details': 'Todos os arquivos podem estar vazios, corrompidos ou n√£o conter texto leg√≠vel.',
                'documentos_analisados': documentos_analisados
            }), 400
        
        # Combinar todos os textos para an√°lise
        texto_completo = "\n\n".join(textos_extraidos)
        print(f"üìù Texto combinado: {len(texto_completo)} caracteres")
        
        # Obter modelo selecionado
        model = request.form.get('model', 'gpt-3.5-turbo')
        
        # Analisar com OpenAI
        try:
            from ai.openai_service import extract_fields_with_openai
            campos = extract_fields_with_openai(texto_completo, model=model, service_type='validacao_juridica')
        except Exception as ia_error:
            print(f"‚ùå Erro na an√°lise pela IA: {ia_error}")
            return jsonify({
                'error': 'Erro ao analisar documentos com IA.',
                'details': str(ia_error),
                'documentos_analisados': documentos_analisados
            }), 500
        
        # Limpar arquivos tempor√°rios
        for temp_file in temp_files:
            if Config.SECURE_PROCESSING:
                secure_manager.cleanup_file(temp_file, user_ip)
        
        return jsonify({
            'success': True,
            'message': f'An√°lise de qualifica√ß√£o conclu√≠da! {len(documentos_analisados)} documentos processados.',
            'documentos_analisados': documentos_analisados,
            'campos': campos,
            'model': model,
            'total_text_length': len(texto_completo),
            'secure_processing': Config.SECURE_PROCESSING
        })
        
    except Exception as e:
        # Garantir limpeza em caso de erro
        for temp_file in temp_files:
            if Config.SECURE_PROCESSING:
                secure_manager.cleanup_file(temp_file, user_ip)
        return jsonify({'error': f'Erro interno do servidor: {str(e)}'}), 500 

@ai_bp.route('/api/validacao-juridica', methods=['POST'])
def process_validacao_juridica():
    """Endpoint para valida√ß√£o jur√≠dica baseada no Checklist 2024-ABR"""
    temp_files = []
    user_ip = request.remote_addr
    
    try:
        if 'files[]' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        
        files = request.files.getlist('files[]')
        if not files or all(file.filename == '' for file in files):
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        
        # Validar arquivos
        valid_files = []
        for file in files:
            if file.filename and allowed_file(file.filename):
                valid_files.append(file)
            else:
                return jsonify({'error': f'Arquivo inv√°lido: {file.filename}. Apenas PDFs s√£o permitidos.'}), 400
        
        if not valid_files:
            return jsonify({'error': 'Nenhum arquivo v√°lido encontrado'}), 400
        
        print(f"üìÅ Processando {len(valid_files)} arquivos para valida√ß√£o jur√≠dica...")
        
        # Processar cada arquivo individualmente
        documentos_analisados = []
        textos_extraidos = []
        
        for i, file in enumerate(valid_files):
            try:
                original_filename = secure_filename(file.filename or f'arquivo_{i}.pdf')
                print(f"üìÑ Processando arquivo {i+1}/{len(valid_files)}: {original_filename}")
                
                # Processar arquivo de forma segura
                if Config.SECURE_PROCESSING:
                    temp_file_path, file_id = secure_manager.process_file_securely(
                        file, original_filename, user_ip
                    )
                else:
                    file_id = str(uuid.uuid4())
                    upload_filename = f"{file_id}_{original_filename}"
                    temp_file_path = os.path.join(Config.UPLOAD_FOLDER, upload_filename)
                    file.save(temp_file_path)
                
                temp_files.append(temp_file_path)
                
                # Extrair texto do PDF
                text_content = ""
                try:
                    # Descriptografar se necess√°rio
                    if Config.SECURE_PROCESSING and Config.ENCRYPT_TEMP_FILES:
                        temp_file_path = secure_manager.decrypt_file(temp_file_path)
                    
                    # Tentar extrair texto diretamente
                    with open(temp_file_path, 'rb') as f:
                        pdf_reader = pypdf.PdfReader(f)
                        for page in pdf_reader.pages:
                            text_content += page.extract_text() + "\n"
                except Exception as e:
                    print(f"‚ùå Erro ao extrair texto de {original_filename}: {str(e)}")
                    text_content = ""
                
                # Limpar e normalizar texto
                text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
                
                # Se n√£o houver texto suficiente, tentar OCR
                if not text_content or len(text_content.strip()) < 50:
                    print(f"üìÑ Tentando OCR para {original_filename}...")
                    try:
                        from ai.ocr_service import process_pdf_with_ocr, extract_text_from_pdf
                        temp_ocr_path = temp_file_path + '_ocr.pdf'
                        ocr_result = process_pdf_with_ocr(temp_file_path, temp_ocr_path)
                        if ocr_result.get('success'):
                            print(f"‚úÖ OCR bem-sucedido para {original_filename}")
                            text_content = extract_text_from_pdf(temp_ocr_path)
                            text_content = re.sub(r'\s+', ' ', text_content.replace('\n', ' ')).strip()
                        else:
                            print(f"‚ùå OCR falhou para {original_filename}")
                    except Exception as ocr_error:
                        print(f"‚ùå Erro durante OCR de {original_filename}: {str(ocr_error)}")
                
                if text_content and len(text_content.strip()) > 10:
                    documentos_analisados.append({
                        'filename': original_filename,
                        'file_id': file_id,
                        'text_length': len(text_content),
                        'text_preview': text_content[:200]
                    })
                    textos_extraidos.append(f"=== DOCUMENTO: {original_filename} ===\n{text_content}\n")
                else:
                    print(f"‚ö†Ô∏è Texto insuficiente em {original_filename}")
                    documentos_analisados.append({
                        'filename': original_filename,
                        'file_id': file_id,
                        'text_length': 0,
                        'error': 'Texto insuficiente ou n√£o leg√≠vel'
                    })
                
            except Exception as e:
                print(f"‚ùå Erro ao processar {original_filename}: {str(e)}")
                documentos_analisados.append({
                    'filename': original_filename,
                    'file_id': str(uuid.uuid4()),
                    'error': str(e)
                })
        
        # Se n√£o h√° textos suficientes, retornar erro
        if not textos_extraidos:
            return jsonify({
                'error': 'N√£o foi poss√≠vel extrair texto suficiente dos documentos.',
                'details': 'Todos os arquivos podem estar vazios, corrompidos ou n√£o conter texto leg√≠vel.',
                'documentos_analisados': documentos_analisados
            }), 400
        
        # Combinar todos os textos para an√°lise
        texto_completo = "\n\n".join(textos_extraidos)
        print(f"üìù Texto combinado: {len(texto_completo)} caracteres")
        
        # Obter modelo selecionado
        model = request.form.get('model', 'gpt-3.5-turbo')
        
        # Analisar com OpenAI
        try:
            from ai.openai_service import extract_fields_with_openai
            campos = extract_fields_with_openai(texto_completo, model=model, service_type='validacao_juridica')
        except Exception as ia_error:
            print(f"‚ùå Erro na an√°lise pela IA: {ia_error}")
            return jsonify({
                'error': 'Erro ao analisar documentos com IA.',
                'details': str(ia_error),
                'documentos_analisados': documentos_analisados
            }), 500
        
        # Limpar arquivos tempor√°rios
        for temp_file in temp_files:
            if Config.SECURE_PROCESSING:
                secure_manager.cleanup_file(temp_file, user_ip)
        
        return jsonify({
            'success': True,
            'message': f'Valida√ß√£o jur√≠dica conclu√≠da! {len(documentos_analisados)} documentos processados.',
            'documentos_analisados': documentos_analisados,
            'campos': campos,
            'model': model,
            'total_text_length': len(texto_completo),
            'secure_processing': Config.SECURE_PROCESSING
        })
        
    except Exception as e:
        # Garantir limpeza em caso de erro
        for temp_file in temp_files:
            if Config.SECURE_PROCESSING:
                secure_manager.cleanup_file(temp_file, user_ip)
        return jsonify({'error': f'Erro interno do servidor: {str(e)}'}), 500 

@ai_bp.route('/api/memorial', methods=['POST'])
def process_memorial():
    """Endpoint para processar arquivos DOCX de memorial de incorpora√ß√£o"""
    import time
    start_time = time.time()
    temp_files = []
    user_ip = request.remote_addr
    
    try:
        if 'files[]' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        
        files = request.files.getlist('files[]')
        if not files or all(file.filename == '' for file in files):
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        
        # Validar arquivos - apenas DOCX
        valid_files = []
        for file in files:
            if file.filename and file.filename.lower().endswith('.docx'):
                valid_files.append(file)
            else:
                return jsonify({'error': f'Arquivo inv√°lido: {file.filename}. Apenas arquivos DOCX s√£o permitidos.'}), 400
        
        if not valid_files:
            return jsonify({'error': 'Nenhum arquivo DOCX v√°lido encontrado'}), 400
        
        print(f"üìÅ Processando {len(valid_files)} arquivos DOCX para memorial...")
        
        # Importar fun√ß√µes do extrator otimizado
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        
        from extrator_memorial_otimizado import processar_arquivo_otimizado as processar_arquivo
        
        # Processar arquivos em paralelo para melhor performance
        todos_dfs = []
        documentos_processados = []
        
        # Usar ThreadPoolExecutor para processamento paralelo
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        def processar_arquivo_single(file_info):
            i, file = file_info
            try:
                original_filename = secure_filename(file.filename or f'arquivo_{i}.docx')
                
                # Processar arquivo de forma segura
                if Config.SECURE_PROCESSING:
                    temp_file_path, file_id = secure_manager.process_file_securely(
                        file, original_filename, user_ip
                    )
                else:
                    file_id = str(uuid.uuid4())
                    upload_filename = f"{file_id}_{original_filename}"
                    temp_file_path = os.path.join(Config.UPLOAD_FOLDER, upload_filename)
                    file.save(temp_file_path)
                
                # Descriptografar arquivo se necess√°rio
                if Config.SECURE_PROCESSING and Config.ENCRYPT_TEMP_FILES:
                    temp_file_path = secure_manager.decrypt_file(temp_file_path)
                
                # Verificar se arquivo existe
                if not os.path.exists(temp_file_path):
                    return {
                        'filename': original_filename,
                        'file_id': file_id,
                        'rows_extracted': 0,
                        'error': 'Arquivo n√£o encontrado ap√≥s descriptografia',
                        'df': None,
                        'temp_file': None
                    }
                
                # Processar arquivo DOCX usando o extrator
                try:
                    df = processar_arquivo(temp_file_path)
                except Exception as process_error:
                    return {
                        'filename': original_filename,
                        'file_id': file_id,
                        'rows_extracted': 0,
                        'error': f'Erro no processamento: {str(process_error)}',
                        'df': None,
                        'temp_file': temp_file_path
                    }
                
                if df is not None and not df.empty:
                    return {
                        'filename': original_filename,
                        'file_id': file_id,
                        'rows_extracted': len(df),
                        'tipo_documento': df['Tipo Documento'].iloc[0] if 'Tipo Documento' in df.columns else 'desconhecido',
                        'df': df,
                        'temp_file': temp_file_path
                    }
                else:
                    return {
                        'filename': original_filename,
                        'file_id': file_id,
                        'rows_extracted': 0,
                        'error': 'Nenhum dado extra√≠do',
                        'df': None,
                        'temp_file': temp_file_path
                    }
                    
            except Exception as e:
                return {
                    'filename': original_filename if 'original_filename' in locals() else f'arquivo_{i}.docx',
                    'file_id': file_id if 'file_id' in locals() else 'unknown',
                    'rows_extracted': 0,
                    'error': str(e),
                    'df': None,
                    'temp_file': temp_file_path if 'temp_file_path' in locals() else None
                }
        
        # Processar arquivos em paralelo
        with ThreadPoolExecutor(max_workers=min(4, len(valid_files))) as executor:
            future_to_file = {
                executor.submit(processar_arquivo_single, (i, file)): i 
                for i, file in enumerate(valid_files)
            }
            
            for future in as_completed(future_to_file):
                result = future.result()
                documentos_processados.append({
                    'filename': result['filename'],
                    'file_id': result['file_id'],
                    'rows_extracted': result['rows_extracted'],
                    'tipo_documento': result.get('tipo_documento', 'desconhecido'),
                    'error': result.get('error', None)
                })
                
                if result['df'] is not None:
                    todos_dfs.append(result['df'])
                
                if result['temp_file']:
                    temp_files.append(result['temp_file'])
        
        # Combinar todos os dados
        if todos_dfs:
            resultado = pd.concat(todos_dfs, ignore_index=True)
            
            # Converter para formato JSON
            dados_json = resultado.to_dict('records')
            
            # Criar arquivo Excel tempor√°rio
            excel_filename = f"memorial_{uuid.uuid4()}.xlsx"
            excel_path = os.path.join(Config.PROCESSED_FOLDER, excel_filename)
            resultado.to_excel(excel_path, index=False)
            
            # Armazenar refer√™ncia do arquivo para download posterior
            memorial_files[excel_filename] = excel_path
            
            # Calcular tempo de processamento
            end_time = time.time()
            processing_time = end_time - start_time
            
            response_data = {
                'success': True,
                'message': f'Processamento conclu√≠do! {len(todos_dfs)} arquivo(s) processado(s)',
                'data': dados_json,
                'columns': resultado.columns.tolist(),
                'excel_file': excel_filename,
                'total_rows': len(resultado),
                'documentos_processados': documentos_processados,
                'processing_time': round(processing_time, 2),
                'resumo': {
                    'arquivos_processados': len(valid_files),
                    'dados_extraidos': len(resultado),
                    'tipos_encontrados': resultado['Formato'].value_counts().to_dict() if 'Formato' in resultado.columns else {}
                }
            }
            
            print(f"‚úÖ Processamento conclu√≠do: {len(resultado)} registros extra√≠dos")
            print(f"üìä Dados JSON criados: {len(dados_json)} registros")
            print(f"üìä Primeiro registro: {dados_json[0] if dados_json else 'N/A'}")
            return jsonify(response_data)
        else:
            return jsonify({
                'success': False,
                'error': 'Nenhum dado foi extra√≠do dos arquivos fornecidos',
                'documentos_processados': documentos_processados
            }), 400
            
    except Exception as e:
        print(f"‚ùå Erro geral no processamento de memorial: {str(e)}")
        return jsonify({'error': f'Erro no processamento: {str(e)}'}), 500
    
    finally:
        # Limpeza de arquivos tempor√°rios
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao limpar arquivo tempor√°rio {temp_file}: {e}") 

@ai_bp.route('/api/memorial/download/<filename>', methods=['GET'])
def download_memorial_excel(filename):
    """Endpoint para download do arquivo Excel do memorial"""
    try:
        if filename not in memorial_files:
            return jsonify({'error': 'Arquivo n√£o encontrado'}), 404
        
        file_path = memorial_files[filename]
        if not os.path.exists(file_path):
            return jsonify({'error': 'Arquivo n√£o existe no servidor'}), 404
        
        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
    except Exception as e:
        print(f"‚ùå Erro ao fazer download do arquivo {filename}: {str(e)}")
        return jsonify({'error': f'Erro ao fazer download: {str(e)}'}), 500 